# Machine-learing-in-Bigdata<br/>
Trong vài năm qua, rất nhiều dữ liệu đã được tạo ra so với hàng thiên niên kỷ của lịch sử loài người trước đây. Dữ liệu này đại diện cho một kho tàng quý giá về giá trị thương mại và cũng là tài liệu tham khảo quan trọng cho các nhà hoạch định chính sách. Nhưng phần lớn giá trị này sẽ vẫn chưa được khai thác - hoặc tệ hơn là bị hiểu sai – trong hoàn cảnh các công cụ cần thiết để xử lý lượng thông tin đáng kinh ngạc vẫn không có sẵn.

<h2>MACHINE LEARNING LÀ GÌ?</h2>

Cốt lõi của học máy bao gồm các thuật toán tự học, phát triển bằng cách liên tục cải tiến nhiệm vụ được giao. Khi được cấu trúc chính xác và cung cấp dữ liệu thích hợp, các thuật toán này cuối cùng sẽ tạo ra kết quả chính xác trong bối cảnh nhận dạng mẫu và mô hình dự đoán.

Đối với các thuật toán học máy, dữ liệu đóng vai trò cốt lõi: càng nhiều càng tốt. Các thuật toán tự tinh chỉnh với dữ liệu mà họ đào tạo giống như cách các vận động viên Olympic trau dồi cơ thể và kỹ năng của họ bằng cách đào tạo mỗi ngày.

Nhiều ngôn ngữ lập trình hoạt động với máy học, bao gồm Python, R, Java, JavaScript và Scala. Python là lựa chọn ưu tiên của nhiều nhà phát triển vì thư viện TensorFlow của nó, cung cấp một hệ sinh thái toàn diện của các công cụ học máy.

<h2>BIG DATA LÀ GÌ?</h2>

Dữ liệu bao gồm số, từ, phép đo và quan sát được định dạng theo cách máy tính có thể xử lý. Dữ liệu lớn đề cập đến tập hợp lớn dữ liệu đó, có cấu trúc hoặc không có cấu trúc.

Kỷ nguyên kỹ thuật số đặt ra một thách thức đối với phần mềm xử lý dữ liệu truyền thống: thông tin trở nên khả dụng với khối lượng, tốc độ và sự đa dạng đến mức vượt xa khả năng tính toán, với đặc trưng là lấy con người làm trung tâm. Và chúng ta có thể mô tả dữ liệu lớn bằng ba chữ “V” sau: khối lượng (volume) , vận tốc (velocity) và sự đa dạng (variety). Khối lượng đề cập đến quy mô của dữ liệu; vận tốc là tốc độ mà dữ liệu được tích lũy; đa dạng đề cập đến các nguồn khác nhau mà dữ liệu được lấy ra.

Hai chữ V khác thường được thêm vào ba chữ V nói trên: Tính xác thực (veracity) đề cập đến tính nhất quán và chắc chắn (hoặc thiếu) trong dữ liệu có nguồn gốc, trong khi giá trị (value) đo lường mức độ hữu ích của dữ liệu được trích xuất từ dữ liệu nhận được.

Phân tích dữ liệu tốt đòi hỏi một người có sự nhạy bén trong kinh doanh, kiến thức lập trình và một bộ kỹ năng toàn diện về toán học và kỹ thuật phân tích. Nhưng làm thế nào một người chuyên nghiệp được trang bị các kỹ thuật truyền thống có thể phân loại thông qua hàng triệu điểm thẻ tín dụng hoặc hàng tỷ tương tác trên mạng xã hội? Đó là nơi mà công nghệ máy học (machine learning) ra đời.

<h2>BIG DATA VÀ MACHINE LEARNING</h2>

Các thuật toán học máy trở nên hiệu quả hơn khi kích thước của bộ dữ liệu đào tạo ngày càng tăng. Vì vậy, khi kết hợp dữ liệu lớn với học máy, chúng ta được lợi gấp đôi: các thuật toán giúp ta theo kịp dòng dữ liệu liên tục, trong khi khối lượng và sự đa dạng của cùng một dữ liệu cung cấp cho các thuật toán và giúp chúng phát triển.

Hãy xem quy trình tích hợp này có thể hoạt động như thế nào:

Bằng cách cung cấp dữ liệu lớn cho thuật toán học máy, chúng ta có thể mong đợi thấy các kết quả được xác định và phân tích, như các mẫu ẩn và phân tích, có thể hỗ trợ trong việc lập mô hình dự đoán.

Đối với một số công ty, các thuật toán này có thể tự động hóa các quy trình trước đây lấy con người làm trung tâm. Nhưng thường xuyên vẫn hơn không, một công ty sẽ xem xét các phát hiện của thuật toán và tìm kiếm chúng để có những thông tin chi tiết có giá trị có thể hướng dẫn hoạt động kinh doanh.

Đây là nơi mọi người quay trở lại vấn đề. Mặc dù AI và phân tích dữ liệu chạy trên các máy tính vượt trội hơn con người rất nhiều, nhưng chúng thiếu khả năng ra quyết định nhất định. Máy tính vẫn chưa tái tạo nhiều đặc điểm vốn có của con người, chẳng hạn như tư duy phản biện, ý định và khả năng sử dụng các phương pháp tiếp cận toàn diện. Nếu không có chuyên gia để cung cấp dữ liệu phù hợp, giá trị của kết quả do thuật toán tạo ra sẽ giảm đi và không có chuyên gia để giải thích kết quả đầu ra của nó, các đề xuất do thuật toán đưa ra có thể ảnh hưởng đến các quyết định của công ty.

<h2>ỨNG DỤNG HỌC MÁY CHO DỮ LIỆU LỚN</h2>

Hãy xem một số ví dụ thực tế chứng minh dữ liệu lớn và máy học có thể hoạt động cùng nhau như thế nào.

<h3>Cloud Networks</h3>

Một công ty nghiên cứu có một lượng lớn dữ liệu y tế mà họ muốn nghiên cứu, nhưng để làm như vậy tại chỗ, công ty cần có máy chủ, lưu trữ trực tuyến, mạng và tài sản bảo mật, tất cả đều tạo ra một khoản chi phí bất hợp lý. Thay vào đó, công ty quyết định đầu tư vào Amazon EMR, một dịch vụ đám mây cung cấp các mô hình phân tích dữ liệu trong khuôn khổ được quản lý.

Các mô hình học máy thuộc loại này bao gồm nhận dạng hình ảnh tăng tốc GPU và phân loại văn bản. Các thuật toán này không học khi chúng được triển khai, vì vậy chúng có thể được phân phối và hỗ trợ bởi mạng phân phối nội dung (CDN).

<h3>Web Scraping</h3>

(Rút trích nội dung trang web)

Giả sử rằng một nhà sản xuất thiết bị nhà bếp tìm hiểu về xu hướng thị trường và xu hướng hài lòng của khách hàng từ các báo cáo hàng quý của nhà bán lẻ. Với mong muốn tìm hiểu những gì các báo cáo có thể còn sót lại, nhà sản xuất quyết định tìm kiếm trên web một lượng lớn dữ liệu hiện có liên quan đến phản hồi trực tuyến của khách hàng và đánh giá sản phẩm. Bằng cách tổng hợp dữ liệu này và cung cấp cho mô hình học sâu, nhà sản xuất học cách cải thiện và mô tả tốt hơn các sản phẩm của mình, giúp tăng doanh số bán hàng.

Mặc dù việc tìm kiếm trên web tạo ra một lượng lớn dữ liệu, nhưng cần lưu ý rằng việc chọn nguồn cho dữ liệu này là phần quan trọng nhất của quy trình.

<h3>Mixed-initiative systems</h3>

(Hệ thống sáng kiến hỗn hợp)

Hệ thống đề xuất đề xuất tiêu đề trên trang chủ Netflix của bạn sử dụng tính năng lọc cộng tác: Hệ thống này sử dụng dữ liệu lớn để theo dõi lịch sử của bạn (và của mọi người khác) và các thuật toán máy học để quyết định nội dung sẽ đề xuất tiếp theo. Ví dụ này cho thấy dữ liệu lớn và máy học giao nhau như thế nào trong lĩnh vực của các hệ thống chủ động hỗn hợp, hoặc tương tác giữa con người với máy tính, mà kết quả của chúng đến từ con người và / hoặc máy móc chủ động.

Tương tự, các nhà sản xuất ô tô thông minh triển khai dữ liệu lớn và máy học trong hệ thống phân tích dự đoán chạy sản phẩm của họ. Ví dụ, ô tô Tesla giao tiếp với người lái xe của họ và phản ứng với các kích thích bên ngoài bằng cách sử dụng dữ liệu để đưa ra quyết định dựa trên thuật toán.

<h2>Các điều cần lưu ý</h2>

Để đạt được kết quả chính xác từ học máy, cần có một số điều kiện tiên quyết. Ngoài một thuật toán học tập được xây dựng tốt, bạn cần dữ liệu sạch, các công cụ có thể mở rộng và ý tưởng rõ ràng về những gì bạn muốn đạt được.

<ul>
  <li>Làm sạch dữ liệu(Data Hygiene)</li>
  <li>Thưc hiện trên dữ liệu thật</li>
  <li>Xác định được mục tiêu</li>
  <li>Công cụ đánh giá(Scaling Tools)</li>
</ul>

<h2>Tóm lược</h2>

Trong bài này, chúng ta đã thảo luận về tính hữu ích của việc áp dụng học máy vào phân tích dữ liệu lớn. Bằng cách lập trình máy để diễn giải dữ liệu lớn mà con người có thể xử lý, chúng ta có thể đưa ra quyết định dựa trên những hiểu biết chính xác hơn.

Chúng tôi cũng đã đề cập đến một số ứng dụng sử dụng dữ liệu lớn với máy học và một số điều cần lưu ý khi bắt đầu quá trình này.
